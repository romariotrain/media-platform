# üéâ Kafka Producer ‚Äî Production-Ready Implementation

## ‚úÖ –ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ

–°–æ–∑–¥–∞–Ω–∞ production-ready —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Kafka Producer —Å:

### 1. üîÑ Retry —Å Exponential Backoff
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ retry –ø—Ä–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ—à–∏–±–∫–∞—Ö
- Exponential backoff: 100ms ‚Üí 200ms ‚Üí 400ms ‚Üí 800ms (cap at 5s)
- –£–º–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ retriable/non-retriable –æ—à–∏–±–æ–∫
- Context cancellation support

### 2. üìù Structured Logging (zerolog)
- –î–µ—Ç–∞–ª—å–Ω—ã–µ –ª–æ–≥–∏ –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- JSON –¥–ª—è production, pretty console –¥–ª—è development
- –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (key, size, duration, attempts)
- –†–∞–∑–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ (debug, info, warn, error)

### 3. üìä –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
- `MessagesPublished` ‚Äî —É—Å–ø–µ—à–Ω–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ
- `MessagesFailed` ‚Äî –ø—Ä–æ–≤–∞–ª–µ–Ω–Ω—ã–µ
- `RetriesTotal` ‚Äî –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ retry
- `AvgPublishTime` ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏

### 4. ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Producer
- –ü–æ–Ω—è—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö
- Defaults –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### 5. üõë Graceful Shutdown
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ —Å flush pending messages
- Timeout 30 —Å–µ–∫—É–Ω–¥ –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–π
- –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ –ª–æ–≥–∞—Ö

### 6. ‚ù§Ô∏è Health Check
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ Producer
- –ê–Ω–∞–ª–∏–∑ error rate
- –ì–æ—Ç–æ–≤–æ –¥–ª—è Kubernetes probes

### 7. üì¶ Batch Publishing
- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
- –ê—Ç–æ–º–∞—Ä–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è (all or nothing)
- Retry –¥–ª—è –≤—Å–µ–≥–æ batch

### 8. üß™ –¢–µ—Å—Ç—ã
- 20+ unit-—Ç–µ—Å—Ç–æ–≤
- –ü–æ–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
- Benchmark –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

---

## üìÅ –§–∞–π–ª—ã

```
outputs/
‚îú‚îÄ‚îÄ producer_improved.go       # ‚ú® –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è Producer
‚îú‚îÄ‚îÄ producer_test.go           # ‚ú® Unit-—Ç–µ—Å—Ç—ã (20+ —Ç–µ—Å—Ç–æ–≤)
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ KAFKA_PRODUCER.md      # üìñ –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ KAFKA_QUICK_START.md   # üöÄ Quick start guide
‚îÇ   ‚îî‚îÄ‚îÄ ...                    # –î—Ä—É–≥–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
‚îî‚îÄ‚îÄ README_KAFKA.md            # üëã –≠—Ç–æ—Ç —Ñ–∞–π–ª
```

---

## üéØ –ö–∞–∫ —á–∏—Ç–∞—Ç—å

### –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞:
1. **–≠—Ç–æ—Ç —Ñ–∞–π–ª** ‚Äî –æ–±–∑–æ—Ä —É–ª—É—á—à–µ–Ω–∏–π
2. `docs/KAFKA_QUICK_START.md` ‚Äî –ø–æ—à–∞–≥–æ–≤–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ

### –î–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π:
1. `docs/KAFKA_PRODUCER.md` ‚Äî –ø–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
    - Retry –ª–æ–≥–∏–∫–∞
    - –ú–µ—Ç—Ä–∏–∫–∏
    - Best practices
    - Troubleshooting

### –î–ª—è –∏–∑—É—á–µ–Ω–∏—è –∫–æ–¥–∞:
1. `producer_improved.go` ‚Äî —É–ª—É—á—à–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
2. `producer_test.go` ‚Äî –ø—Ä–∏–º–µ—Ä—ã —Ç–µ—Å—Ç–æ–≤

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ zerolog (–µ—Å–ª–∏ –µ—â—ë –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)

```bash
go get github.com/rs/zerolog
```

### 2. –ó–∞–º–µ–Ω–∏—Ç–µ producer.go

```bash
cd /path/to/media-platform

# Backup
cp internal/media/kafka/producer.go internal/media/kafka/producer_old.go

# –ó–∞–º–µ–Ω–∏—Ç–µ
cp producer_improved.go internal/media/kafka/producer.go
```

### 3. –û–±–Ω–æ–≤–∏—Ç–µ —Å–æ–∑–¥–∞–Ω–∏–µ Producer

**–ë—ã–ª–æ:**
```go
producer := kafka.NewProducer([]string{"localhost:9092"}, "events")
```

**–°—Ç–∞–ª–æ:**
```go
logger := zerolog.New(os.Stdout).With().Timestamp().Logger()

producer, err := kafka.NewProducer(kafka.ProducerConfig{
    Brokers: []string{"localhost:9092"},
    Topic:   "events.media.created",
    Logger:  logger,
})
if err != nil {
    log.Fatal(err)
}
defer producer.Close()
```

**–î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:** `docs/KAFKA_QUICK_START.md`

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: –î–æ –∏ –ü–æ—Å–ª–µ

### –ö–æ–¥

**–î–æ (–ø—Ä–æ—Å—Ç–æ–π, –Ω–æ —Ö—Ä—É–ø–∫–∏–π):**
```go
func (p *Producer) Publish(ctx context.Context, key string, value []byte) error {
    err := p.writer.WriteMessages(ctx, kafkago.Message{
        Key:   []byte(key),
        Value: value,
    })
    if err != nil {
        return fmt.Errorf("kafka publish: %w", err)
    }
    return nil
}
```

**–ü–æ—Å–ª–µ (production-ready):**
```go
func (p *Producer) Publish(ctx context.Context, key string, value []byte) error {
    // ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ closed
    // ‚úÖ Structured logging
    // ‚úÖ Retry loop —Å exponential backoff
    // ‚úÖ Retriable/non-retriable error detection
    // ‚úÖ Metrics tracking
    // ‚úÖ Context cancellation support
    // 350+ —Å—Ç—Ä–æ–∫ –Ω–∞–¥—ë–∂–Ω–æ–≥–æ –∫–æ–¥–∞
}
```

### –õ–æ–≥–∏

**–î–æ:**
```
(–Ω–∏—á–µ–≥–æ)
```

**–ü–æ—Å–ª–µ (JSON):**
```json
{
  "level": "info",
  "component": "kafka_producer",
  "topic": "events.media.created",
  "brokers": ["localhost:9092"],
  "max_retries": 3,
  "time": "2026-01-18T14:00:00Z",
  "message": "kafka producer created"
}

{
  "level": "warn",
  "component": "kafka_producer",
  "attempt": 2,
  "backoff": 100000000,
  "error": "connection refused",
  "message": "retrying publish"
}

{
  "level": "info",
  "component": "kafka_producer",
  "duration": 150000000,
  "attempts": 2,
  "message": "message published successfully"
}
```

### –ü–æ–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö

**–î–æ:**
```
Error: connection refused
(fails immediately, event lost)
```

**–ü–æ—Å–ª–µ:**
```
Attempt 1: connection refused
Wait 100ms...
Attempt 2: connection refused
Wait 200ms...
Attempt 3: connection refused
Wait 400ms...
Attempt 4: SUCCESS! ‚úÖ
```

### –ú–µ—Ç—Ä–∏–∫–∏

**–î–æ:**
```
(–Ω–∏—á–µ–≥–æ)
```

**–ü–æ—Å–ª–µ:**
```go
metrics := producer.GetMetrics()
// MessagesPublished: 10000
// MessagesFailed: 50
// RetriesTotal: 200
// AvgPublishTime: 45ms

// –ú–æ–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ Prometheus
kafkaMessagesPublished.Set(float64(metrics.MessagesPublished))
```

---

## üéì –ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏

### Retry Strategy

```
Error ‚Üí Retriable? ‚Üí No ‚Üí Return error immediately
         ‚Üì Yes
    Exponential backoff
         ‚Üì
    Retry (up to MaxRetries times)
```

**Retriable errors:**
- Connection refused/reset
- Timeout
- Leader not available
- Temporary failures

**Non-retriable errors:**
- Invalid message
- Message too large
- Authorization failed
- Context cancelled

### Exponential Backoff

```
Attempt 1: immediate (0ms)
Attempt 2: 100ms  (baseBackoff * 2^0)
Attempt 3: 200ms  (baseBackoff * 2^1)
Attempt 4: 400ms  (baseBackoff * 2^2)
Attempt 5: 800ms  (baseBackoff * 2^3)
Attempt 6: 1600ms (baseBackoff * 2^4)
...
Max: 5000ms (capped)
```

### –ú–µ—Ç—Ä–∏–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

```go
type ProducerMetrics struct {
    MessagesPublished atomic.Int64 // thread-safe
    MessagesFailed    atomic.Int64
    RetriesTotal      atomic.Int64
    PublishDuration   atomic.Int64
}

// –õ—é–±–∞—è –≥–æ—Ä—É—Ç–∏–Ω–∞ –º–æ–∂–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ —á–∏—Ç–∞—Ç—å/–ø–∏—Å–∞—Ç—å
metrics.MessagesPublished.Add(1)
count := metrics.MessagesPublished.Load()
```

---

## üí° –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ë–∞–∑–æ–≤–æ–µ

```go
logger := zerolog.New(os.Stdout).With().Timestamp().Logger()

producer, err := kafka.NewProducer(kafka.ProducerConfig{
    Brokers: []string{"localhost:9092"},
    Topic:   "events",
    Logger:  logger,
})
if err != nil {
    log.Fatal(err)
}
defer producer.Close()

ctx := context.Background()
err = producer.Publish(ctx, "key", []byte("value"))
```

### –° custom –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π

```go
producer, err := kafka.NewProducer(kafka.ProducerConfig{
    Brokers:      []string{"kafka1:9092", "kafka2:9092"},
    Topic:        "events",
    MaxRetries:   5,                      // –±–æ–ª—å—à–µ retry
    RetryBackoff: 200 * time.Millisecond, // –±–æ–ª—å—à–µ backoff
    WriteTimeout: 5 * time.Second,
    BatchSize:    50,
    Async:        true,
    Logger:       logger,
})
```

### –° timeout

```go
ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
defer cancel()

err := producer.Publish(ctx, "key", value)
if errors.Is(err, context.DeadlineExceeded) {
    log.Println("Publish timed out")
}
```

### Batch publishing

```go
messages := []kafka.Message{
    {Key: "event-1", Value: []byte(`{"id":"1"}`)},
    {Key: "event-2", Value: []byte(`{"id":"2"}`)},
    {Key: "event-3", Value: []byte(`{"id":"3"}`)},
}

err := producer.PublishBatch(ctx, messages)
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫

```go
ticker := time.NewTicker(1 * time.Minute)
defer ticker.Stop()

for range ticker.C {
    metrics := producer.GetMetrics()
    
    logger.Info().
        Int64("published", metrics.MessagesPublished).
        Int64("failed", metrics.MessagesFailed).
        Int64("retries", metrics.RetriesTotal).
        Dur("avg_time", metrics.AvgPublishTime).
        Msg("kafka metrics")
    
    // Alert –µ—Å–ª–∏ error rate > 10%
    if metrics.MessagesPublished > 0 {
        errorRate := float64(metrics.MessagesFailed) / float64(metrics.MessagesPublished)
        if errorRate > 0.1 {
            alerting.Send("High Kafka error rate: %.2f%%", errorRate*100)
        }
    }
}
```

### Health check

```go
func healthHandler(w http.ResponseWriter, r *http.Request) {
    ctx, cancel := context.WithTimeout(r.Context(), 5*time.Second)
    defer cancel()
    
    if err := producer.HealthCheck(ctx); err != nil {
        http.Error(w, err.Error(), http.StatusServiceUnavailable)
        return
    }
    
    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(map[string]string{"status": "healthy"})
}
```

---

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

### –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤

```bash
# –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ç–µ—Å—Ç—ã
cp producer_test.go internal/media/kafka/

# –ó–∞–ø—É—Å—Ç–∏—Ç–µ
go test ./internal/media/kafka/...

# –° verbose
go test -v ./internal/media/kafka/...

# –° –ø–æ–∫—Ä—ã—Ç–∏–µ–º
go test -cover ./internal/media/kafka/...

# Benchmark
go test -bench=. ./internal/media/kafka/...
```

### –ü–æ–∫—Ä—ã—Ç–∏–µ

- ‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ Producer (—É—Å–ø–µ—Ö + –≤–∞–ª–∏–¥–∞—Ü–∏—è)
- ‚úÖ Defaults –∏ custom config
- ‚úÖ Retriable/non-retriable errors
- ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ (published, failed, retries, avg time)
- ‚úÖ Close –∏ double-close
- ‚úÖ Publish after close
- ‚úÖ Batch publishing
- ‚úÖ Health check
- ‚úÖ Context cancellation

**–í—Å–µ–≥–æ:** 20+ —Ç–µ—Å—Ç–æ–≤ + 1 benchmark

---

## üéØ Best Practices

### 1. Context timeout

```go
// ‚úÖ Good
ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
defer cancel()
err := producer.Publish(ctx, key, value)

// ‚ùå Bad
err := producer.Publish(context.Background(), key, value)
```

### 2. Graceful shutdown

```go
defer func() {
    logger.Info().Msg("closing kafka producer")
    if err := producer.Close(); err != nil {
        logger.Error().Err(err).Msg("error closing producer")
    }
}()
```

### 3. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

```go
// –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
go func() {
    ticker := time.NewTicker(1 * time.Minute)
    for range ticker.C {
        metrics := producer.GetMetrics()
        // Check error rate, avg time, etc.
    }
}()
```

### 4. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ retry

```go
// –ö—Ä–∏—Ç–∏—á–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
producer, _ := kafka.NewProducer(kafka.ProducerConfig{
    MaxRetries:   10,
    RetryBackoff: 500 * time.Millisecond,
})

// –ù–µ–∫—Ä–∏—Ç–∏—á–Ω—ã–µ
producer, _ := kafka.NewProducer(kafka.ProducerConfig{
    MaxRetries:   1,
    RetryBackoff: 50 * time.Millisecond,
})
```

---

## üêõ Troubleshooting

### –í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è fail

**–°–∏–º–ø—Ç–æ–º—ã:**
```
MessagesFailed: 1000
MessagesPublished: 0
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞:**
```bash
# Kafka —Ä–∞–±–æ—Ç–∞–µ—Ç?
docker ps | grep kafka

# Connectivity?
telnet localhost 9092
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
docker compose -f deploy/docker-compose.yml up -d kafka
```

### –ú–Ω–æ–≥–æ retry

**–°–∏–º–ø—Ç–æ–º—ã:**
```
RetriesTotal: 5000
MessagesPublished: 1000
```

**–ü—Ä–∏—á–∏–Ω—ã:** Kafka overloaded, network issues

**–†–µ—à–µ–Ω–∏–µ:**
```go
// –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ batch
err := producer.PublishBatch(ctx, messages)

// –£–≤–µ–ª–∏—á—å—Ç–µ backoff
producer, _ := kafka.NewProducer(kafka.ProducerConfig{
    RetryBackoff: 500 * time.Millisecond,
})
```

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è

**–°–∏–º–ø—Ç–æ–º—ã:**
```
AvgPublishTime: 2s
```

**–†–µ—à–µ–Ω–∏–µ:**
```go
// Async mode
producer, _ := kafka.NewProducer(kafka.ProducerConfig{
    Async: true,
})

// Batch
err := producer.PublishBatch(ctx, messages)
```

**–î–µ—Ç–∞–ª—å–Ω—ã–π troubleshooting:** `docs/KAFKA_PRODUCER.md`

---

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### –§–∞–π–ª—ã

1. **README_KAFKA.md** (—ç—Ç–æ—Ç —Ñ–∞–π–ª) ‚Äî –æ–±–∑–æ—Ä —É–ª—É—á—à–µ–Ω–∏–π
2. **docs/KAFKA_QUICK_START.md** ‚Äî –ø–æ—à–∞–≥–æ–≤–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ
3. **docs/KAFKA_PRODUCER.md** ‚Äî –ø–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### –í –∫–æ–¥–µ

- `producer_improved.go` ‚Äî 500+ —Å—Ç—Ä–æ–∫ production-ready –∫–æ–¥–∞
- `producer_test.go` ‚Äî 20+ —Ç–µ—Å—Ç–æ–≤

---

## ‚úÖ –ß–µ–∫-–ª–∏—Å—Ç

- [ ] –ü—Ä–æ—á–∏—Ç–∞–ª —ç—Ç–æ—Ç README
- [ ] –ü—Ä–æ—á–∏—Ç–∞–ª KAFKA_QUICK_START.md
- [ ] –£—Å—Ç–∞–Ω–æ–≤–∏–ª zerolog
- [ ] –ó–∞–º–µ–Ω–∏–ª producer.go
- [ ] –û–±–Ω–æ–≤–∏–ª –∫–æ–¥ —Å–æ–∑–¥–∞–Ω–∏—è Producer
- [ ] –î–æ–±–∞–≤–∏–ª graceful shutdown
- [ ] –ó–∞–ø—É—Å—Ç–∏–ª —Ç–µ—Å—Ç—ã
- [ ] –ü—Ä–æ–≤–µ—Ä–∏–ª —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏
- [ ] –ù–∞—Å—Ç—Ä–æ–∏–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫
- [ ] –î–æ–±–∞–≤–∏–ª health check

---

## üéÅ –ë–æ–Ω—É—Å: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Outbox Publisher

–£–ª—É—á—à–µ–Ω–Ω—ã–π Kafka Producer –∏–¥–µ–∞–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å Outbox Publisher:

```go
// –°–æ–∑–¥–∞—ë–º Kafka Producer
kafkaProducer, err := kafka.NewProducer(kafka.ProducerConfig{
    Brokers: []string{"localhost:9092"},
    Topic:   "events.media.created",
    Logger:  logger,
})

// –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤ Outbox Publisher
outboxPublisher, err := outbox.NewPublisher(outbox.PublisherConfig{
    OutboxRepo: outboxRepo,
    Producer:   kafkaProducer, // –Ω–∞—à —É–ª—É—á—à–µ–Ω–Ω—ã–π Producer!
    Interval:   5 * time.Second,
    BatchSize:  100,
    Logger:     logger,
})
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ Retry –ª–æ–≥–∏–∫–∞ –¥–ª—è —Å–æ–±—ã—Ç–∏–π –∏–∑ Outbox
- ‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–µ –ª–æ–≥–∏ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
- ‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è Kafka operations
- ‚úÖ Graceful shutdown –¥–ª—è –æ–±–æ–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

---

## üöÄ –ò—Ç–æ–≥–æ

–í—ã –ø–æ–ª—É—á–∏–ª–∏:

1. ‚úÖ **Production-ready Kafka Producer** —Å retry, logging, metrics
2. ‚úÖ **20+ —Ç–µ—Å—Ç–æ–≤** ‚Äî –ø–æ–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
3. ‚úÖ **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é** ‚Äî 3 –ø–æ–¥—Ä–æ–±–Ω—ã—Ö —Ñ–∞–π–ª–∞
4. ‚úÖ **–ü—Ä–∏–º–µ—Ä—ã** ‚Äî –≥–æ—Ç–æ–≤—ã–µ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é snippets
5. ‚úÖ **Best practices** ‚Äî –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ

**–í—Å—ë –≥–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!** üöÄ

–°–ª–µ–¥—É–π `docs/KAFKA_QUICK_START.md` –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è.

---

**P.S.** –≠—Ç–æ—Ç Producer –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –¥–ª—è Outbox Pattern, –Ω–æ –∏ –¥–ª—è –ª—é–±–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –≤ Kafka. –û–Ω —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏ production-ready! üí™